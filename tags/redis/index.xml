<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Redis on Airplane</title><link>https://vinci-217.github.io/tags/redis/</link><description>Recent content in Redis on Airplane created by</description><generator>Hugo -- gohugo.io</generator><language>zn-ch</language><lastBuildDate>Thu, 06 Mar 2025 17:07:00 +0800</lastBuildDate><atom:link href="https://vinci-217.github.io/tags/redis/index.xml" rel="self" type="application/rss+xml"/><item><title>缓存和数据库一致性解决策略</title><link>https://vinci-217.github.io/blog/cache-consistency/</link><pubDate>Thu, 06 Mar 2025 17:07:00 +0800</pubDate><guid>https://vinci-217.github.io/blog/cache-consistency/</guid><description>&lt;p>为了能让用户获取到数据更快，我们采用缓存的策略。但是在更新操作时，我们需要保证缓存和数据库的数据一致性。本文介绍几种常用的缓存和数据库一致性解决策略。&lt;/p>
&lt;h2 id="cache-aside">Cache Aside&lt;/h2>
&lt;p>Cache Asside即旁路缓存，是保证缓存和数据库一致性常用的一种策略。当面临数据更新时，先更新数据库，然后删除缓存。&lt;/p>
&lt;p>这种模型会出现一种小的错误，导致读取的数据和实际的数据不一致（如图）。其主要原因是更新数据库的数据以后，还没来得及删除缓存，读取请求就打到了缓存中。不过这种可能性比较小，并且毕竟是读取请求，可以容忍一定时间的数据不一致问题。&lt;/p>
&lt;p>&lt;img src="image/image.png" alt="图片来自马丁">&lt;/p>
&lt;p>还有一种相对影响较大的问题，就是可能会出现查询数据不存在，并且放入缓存的请求在更新缓存之后，就导致了缓存了错误的数据的情况。&lt;/p>
&lt;p>&lt;img src="image/image-1.png" alt="图片来自马丁">&lt;/p>
&lt;p>不过这种情况的可能性也及其小，实际业务中可以容忍。&lt;/p>
&lt;h2 id="消息队列最终一致性">消息队列最终一致性&lt;/h2>
&lt;p>&lt;img src="image/image-2.png" alt="图片来自马丁">&lt;/p>
&lt;p>这种方法通过消息队列将更新数据库的操作和更新缓存的操作解耦：当更新完数据库时，先将消息放入消息队列，然后消费者消费消息，更新缓存。这种方式可以保证缓存和数据库的数据一致性，但是会引入一定的延迟。&lt;/p></description></item><item><title>一文归纳数据库集群技术要点</title><link>https://vinci-217.github.io/blog/database-cluster/</link><pubDate>Fri, 07 Feb 2025 19:52:18 +0800</pubDate><guid>https://vinci-217.github.io/blog/database-cluster/</guid><description>&lt;p>数据库是服务端开发离不开的中间件，为了提高大型项目中数据库的可用性，常常通过集群的方式部署数据库。本文将从数据库集群的技术要点出发，介绍基于 MySQL 和 Redis 的数据库集群方案。&lt;/p>
&lt;h2 id="mysql">MySQL&lt;/h2>
&lt;p>MySQL 最初是一种单机的数据库系统，他的集群出现主要是为了应对高并发读写和数据库宕机的场景。针对这样的场景，MySQL 采用了多个服务集群部署、读写分离等策略来应对。MySQL 集群的方式有很多种，目的都是为了提高其可用性。&lt;/p>
&lt;h3 id="读写分离">读写分离&lt;/h3>
&lt;p>读写分离是提高 MySQL 并发量的一种策略，其含义是使用多个具有相同数据的 MySQL 实例来分担大量查询请求。其本质上是有一个或多个主节点作为客户端写入的实例，其他的实例作为备份节点，提供只读的服务。&lt;/p>
&lt;p>读写分离本质上相当于一种请求的负载均衡，将读请求分担到多个从节点，将写请求分担到主节点。但也会面临一些集群的问题。根据经典的 CAP 理论，网络分区容忍性必须保证，那么一致性和可用性就成为一个值得权衡的点。最明显的就是由于主从同步的延迟，可能会出现数据不一致的问题。&lt;/p>
&lt;p>&lt;img src="image/image.png" alt="MySQL 集群架构">&lt;/p>
&lt;h3 id="集群模式">集群模式&lt;/h3>
&lt;h4 id="mysql-replication">MySQL Replication&lt;/h4>
&lt;p>MySQL Replication 最基本的 MySQL 集群功能，基于一主多从的架构，主库负责写数据，从库负责读数据。主库会将数据变更记录在 binlog 中，从库通过读取主库的 binlog 来获取主库的最新数据，相当于主库的 sql 语句在从库上又执行了一遍。&lt;/p>
&lt;h4 id="mysql-fabirc">MySQL Fabirc&lt;/h4>
&lt;p>MySQL Fabric 是在 MySQL Replication 的基础上，增加的故障检测与转移、自动数据分片的功能。但是依然是基于一主多从的架构，主库负责写数据，从库负责读数据。MySQL Fabric 只有一个主节点，但是当主节点挂掉以后，会从从节点中选一个来当主节点。&lt;/p>
&lt;h4 id="mysql-cluster">MySQL Cluster&lt;/h4>
&lt;p>MySQL Cluster 是一种多主多从的架构，也是由 MySQL 官方提供。他的高可用、负载均衡、伸缩性都很优秀，但是架构模式和原理很复杂，并且只能使用 NDB 存储引擎而不是 InnoDB 存储引擎（比如在事务隔离级别上只支持 Read Committed）。&lt;/p>
&lt;h3 id="主从同步">主从同步&lt;/h3>
&lt;p>MySQL 的集群之间的数据同步是基于 binlog 的。binlog 是 MySQL 服务器的二进制日志，记录了对数据库的修改，包括增删改操作。通过 binlog，可以将数据同步到其他的 MySQL 服务器，实现数据库集群的数据一致性。&lt;/p>
&lt;p>binlog 有三种格式，一种是 statement，一种是 row，还有一种是 mixed。statement 格式的 binlog 记录的是 SQL 语句的原始文本，row 格式的 binlog 记录的是每行数据的修改，mixed 格式的 binlog 既记录 SQL 语句，又记录每行数据的修改。&lt;/p>
&lt;p>假如我们执行一个删除的 SQL，&lt;code>delete from table1 where id &amp;gt; 100 limit 1&lt;/code>，由于 limit 这个命令，可能导致从库具体的这个 limit 1 和主库的 limit 1 不是同一行数据，所以造成误删的风险，那么 row 格式的 binlog 就应运而生了。但是由于每次记录 row 类型的 binlog 对内存开销太大，所以就有了 mixed 格式的 binlog——既记录 SQL 语句，又记录每行数据的修改，做了两者之间的权衡。&lt;/p>
&lt;p>不同的集群模式主从同步的方式也不太一样，但大致流程相似：&lt;/p>
&lt;ol>
&lt;li>主库接收到客户端的更新请求，执行更新操作并写入 binlog&lt;/li>
&lt;li>从库在主从之间简历长连接&lt;/li>
&lt;li>主库的 dump_tread 从本地读取 binlog 给从库&lt;/li>
&lt;li>从库获取到主库的 binlog 后存储到本地，成为 relay log&lt;/li>
&lt;li>从库的 sql_thread 读取 relay log，解析出具体的 sql 语句，执行 sql 语句&lt;/li>
&lt;/ol>
&lt;p>主从库之间的数据借助 binlog 进行复制，数据复制的一般分为同步和异步两种。同步复制就是主库接收到写请求完成以后，会等待副本的写请求也完成，才返回客户端，而异步复制就是主库直接返回客户端，不等待副本的写请求完成，然后让异步线程去处理副本的写请求。很经典的问题出现了：同步复制能够很好保证数据一致性，但是性能差；异步复制反之。&lt;/p>
&lt;p>其实除了我们讨论的主从复制，还有多主复制、无主复制等演化得到的不同的主从模型，此处就不在深入讨论了。&lt;/p>
&lt;p>MySQL 5.7 版本引入了半同步复制。异步复制是事务线程完全不等复制响应。同步复制是事务线程要等所有复制响应。半同步复制就是等待一部分复制响应就认为成功。&lt;/p>
&lt;p>比较重要的是半同步复制。&lt;/p>
&lt;p>半同步复制过程中有一个参数“rpl_semi_sync_master_wait_no_slave”，默认值是 1，表示等待至少一个从库的响应，如果设置为大于 1 的值，表示等待指定数量的从库的响应。其本质上是等主库生成 binlog，从库接收到 binlog，但没有等到写入 relay log，就给主库一个确认。&lt;/p>
&lt;p>还有一个是”rpl_semi_sync_master_wait_point“，表示的是主库提交事务之前等待复制还是提交事务之后等待复制。，默认是先等待复制（AFTER_SYNC），再提交事务，这样不会完全丢数据。相反的配置（AFTER_COMMIT）是先提交事务，再等待复制，这样会性能好一点，但是存在宕机丢数据的风险。&lt;/p>
&lt;p>如果主库提交事务的线程等待复制的时间超时了，那么这种情况下 MySQL 会自动降级为异步复制模式。&lt;/p>
&lt;p>一种优化方式是增强半同步复制——基于两阶段提交的优化。&lt;/p>
&lt;p>&lt;a href="https://xiaolincoding.com/mysql/log/how_update.html#%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84">两阶段提交&lt;/a>是 MySQL 用于利用类似分布式 XA 两阶段提交（分布式一致性的一种解决方法），解决 redo log 和 binlog 一致性的一种日志提交方式。&lt;/p>
&lt;p>&lt;img src="image/image-1.png" alt="两阶段提交">&lt;/p>
&lt;p>增强半同步复制不同于普通的半同步复制，它的等待备库返回 ACK 的时间点是最后的 commit 之后（即图片中的步骤三之后）。步骤二生成 binlog 以后发给从库，从库对得到的 binlog 同步完毕以后返回给主库 ack，主库进行步骤三 commit，然后认为同步完毕。
这样如果日志没有传给从库，主库也不会 commit，保障了数据同步一致性。&lt;/p>
&lt;h3 id="主从延迟">主从延迟&lt;/h3>
&lt;p>主从延迟指的是从主库生成 binlog 到从库接收到 binlog 然后执行完对应的事务之间的延迟。&lt;/p>
&lt;p>主从延迟的原因主要有以下几点：&lt;/p>
&lt;ol>
&lt;li>网络延迟：主从之间网络延迟越长，主从延迟就越大。&lt;/li>
&lt;li>某些情况下，从库的机器性能比主库的机器性能差。&lt;/li>
&lt;li>从库的读压力过大&lt;/li>
&lt;li>慢 sql、大事务造成的时间等待，binlog 生成速度慢，导致从库延迟。&lt;/li>
&lt;/ol>
&lt;p>针对主从同步的延迟，有一些可靠性和可用性的策略调整，如双 M（两个主机）、半同步复制等针对主从的调度策略，会减少主从延迟。&lt;/p>
&lt;h3 id="分库分表">分库分表&lt;/h3>
&lt;p>分库分表主要是为了解决两个问题：解决查询慢的问题，解决高并发的问题。&lt;/p>
&lt;p>解决查询慢的问题，其实只需要减少每次查询时检索的数据量就行了。例如：即使数据量很大的情况，如果能走索引，那么查询扫描的次数也很少，并不需要全表扫描检索很多次，所以性能也很好。当然我们考虑的肯定是不全能走索引的情况，那么除了建立合适的索引之外，还可以考虑&lt;strong>分表&lt;/strong>。只需要将查询的数据分散到多个表中，每次查询对应的表，这样检索的数据就变少了，查询效率也变快了。&lt;/p>
&lt;p>解决高并发的问题，这就需要&lt;strong>分库&lt;/strong>了。因为有时候查询的压力过大，并发量过多，一个数据库实例就容易扛不住导致宕机。通过分库的方式，就可以把并发请分散到多个实例中，从而缓解一个实例的压力。&lt;/p>
&lt;p>分库分表一般垂直和水平两种，一般来讲，垂直分库分表主要是将原来一张表里面的字段拆分开，分散到多个表中，其目的是加快查询效率，减少一些不必要的字段。水平分库分表主要是为了将数据分散开，一般会选择某种哈希算法，针对表的 id 进行水平划分，起到负载均衡的作用。水平分库分表也是解决海量存储的一种策略，即使是走索引的查询，数据量少了也会减少磁盘 IO 次数，从而加快查询效率。&lt;/p>
&lt;h2 id="redis">Redis&lt;/h2>
&lt;p>像 MySQL 的同步基于 binlog 一样，Redis 的同步也是基于日志的。主要有 AOF（Append Only File）和 RDB（Redis DataBase）两种方式。AOF 是 Redis 在每行数据操作以后记录同样的操作语句，而 RDB 是内存快照。当然也各有利弊，这里不在赘述。&lt;/p>
&lt;p>Redis 的集群主要有主从集群、哨兵集群、切片集群等模式，其目的都是为了保证 Redis 的高可用性。&lt;/p>
&lt;h3 id="主从集群">主从集群&lt;/h3>
&lt;p>主从集群是 Redis 的一种集群模式，其原理是主节点负责写数据，从节点负责读数据。主节点将数据同步到从节点，从节点通过读取主节点的数据来获取最新的数据，类似于 MySQL 的主从集群。&lt;/p>
&lt;p>主从同步主要有三个阶段：&lt;/p>
&lt;ol>
&lt;li>连接阶段：从库给主库发送 psync 命令表示要进行同步，里面包括的了主库的 runID 和复制进度 offset（第一次为-1）。主库收到收到以后会返回 FULLRESYNC 命令，并带上主库的 runID 和 offset。（第一次全量复制）&lt;/li>
&lt;li>发送 RDB：主库执行 bgsave 命令生成 RDB 文件并发送给从库，从库接收到以后清空当前数据库，然后加载 RDB 文件。由于 bgsave 是后台复制一个子进程，复制了操作系统的页表，所以不会阻塞当前进程，主库当前仍然可以接受读写请求。但是在同步过程中的写入操作并不会即时写入 RDB 文件，而是会写入 replication buffer，在 RDB 发送完成以后发送给从库。&lt;/li>
&lt;li>发送 replication buffer：主库将 replication buffer 中的数据发送给从库，从库接收到以后写入磁盘。&lt;/li>
&lt;/ol>
&lt;p>有时候为了减轻主库的压力，会采用主-从-从的多级复制模式，并且主库和从库直接回维持一个长连接，从而减少时间开销，尽可能减少同步数据的不一致性，但这样同样会面临网络不稳定的问题。针对网络不稳定的问题，Redis 还有一种应对的策略，就是增量复制。&lt;/p>
&lt;p>增量同步通过 repl_backlog_buffer 这个环形的数据结构实现（有点像 redolog 的写入缓冲区），其中主库在前面写，从库在后面读，前后像是一种追赶的关系。理想情况下，两者是同时进行的关系，也就是说时时刻刻他们俩的指针都在同一位置。但事实上他们之间会有差距，所以当网络突然断掉，从库在向主库发送 psync 命令，表示要建立链接的时候，就会将自己的在 repl_backlog_buffer 中读到哪个位置的数据发给主库，那么接下来主库只需要发送对应位置之后的数据就可以了，不用全量发送，从而实现了增量发送的目的。&lt;/p>
&lt;p>&lt;img src="image/image-2.png" alt="repl_bcaklog_buffer">&lt;/p>
&lt;p>但是由于这个缓冲区本身是一个环形的设计，所以有可能会发生主库写入数据覆盖了之前的数据，但是从库还没有读取这个数据的情况。我猜想这个数据结构设计本意是为了减少空间使用且不用使用数据淘汰策略（覆盖写入自动淘汰），减少时间空间开销，但是也引出了这种问题。我们只能认为通过增大这个缓冲区的大小减少这个事情发生的可能性。&lt;/p>
&lt;h3 id="哨兵集群">哨兵集群&lt;/h3>
&lt;p>为了保证 Redis 的高可用性，我们需要考虑主库也可能宕机的情况。但是主库宕机也很复杂，我们需要判断主库真的挂了吗？选哪个当从库？新的主库怎么和其他从库链接呢？由此引入哨兵机制，帮助选主并与其他从库同步。&lt;/p>
&lt;p>哨兵在此处的作用类似于注册中心，他的主要作用是监控、选主、通知，其本身也是一个 Redis 实例。&lt;/p>
&lt;ol>
&lt;li>监控：哨兵会不断向主库和从库发送 Ping 命令，如果一段时间没有回复，那么就认为主观下线。&lt;/li>
&lt;li>选主：哨兵会对从库直接进行判断，选择最优的一个作为主库。主要是考虑优先级（用户配置），复制进度（之前提到的增量复制的进度），和 RedisID 决定。&lt;/li>
&lt;li>通知：哨兵会将选出的主库信息发送 replicaof 命令给其他从库，其他从库会更新自己的主库信息。&lt;/li>
&lt;/ol>
&lt;p>实际上，哨兵本身也是集群部署，在判断 Redis 实例存活/宕机时，会采用投票机制（少数服从多数）来判断数据库是否客观下线。&lt;/p>
&lt;p>哨兵集群中真正执行将从库升级为主库的节点叫 Leader 节点，这个节点也是由其他哨兵实例投票选举+大于用户配置的参数决定。&lt;/p>
&lt;p>哨兵模式可能会出现脑裂的问题。脑裂就是一个大脑裂开成两个，对应到 Redis 集群中就是出现了两个主节点。节点 A 一开始是主节点，由于网络抖动被认为下线了，于是哨兵集群选举了一个新节点 B 作为主节点。一段时间以后节点 A 复活了，集群会把 A 降级为从节点。既然是从节点，就需要与主节点 B 同步数据。由于 A 作为从节点，B 作为主节点，他们是第一次同步数据，所以 A 会清空自己的数据，将 B 的 RDB 完全读入。但是由于 B 是被选出来的新主节点，他里面的数据和之前的 A 并不是完全相同（他们之间的同步不是强一致性，是最终一致性），所以在 A 作为主节点的时候，有些数据 A 里面有，B 里面没有。那么 A 作为从节点的时候，清空了自己的数据，那么就可能会造成数据丢失。&lt;/p>
&lt;p>在 Redis 中有两个配置的属性：&lt;/p>
&lt;ol>
&lt;li>min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。&lt;/li>
&lt;li>min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。&lt;/li>
&lt;/ol>
&lt;p>实际上这种配置本质上是限制了节点 A 的读写，只允许了新主库 B 的读写，从时间角度上减少了脑裂的可能性。&lt;/p>
&lt;h3 id="切片集群">切片集群&lt;/h3>
&lt;p>切片集群类似于 MySQL 的分库分表，将数据切分到多个 Redis 实例中，从而实现数据横向扩展。官方提供了一个 Redis Cluster 方案，用来实现切片集群。&lt;/p>
&lt;p>Redis Cluster 方案采用 Hash Slot 来处理数据和实例之间的映射关系，一个切片集群由 16384 个哈希槽。首先根据键值对的 key 根据 CRC16 算法计算一个 16bit 的值，然后用这个 16 位的值对 16384 取模，得到映射对应的哈希槽位。Redis Cluster 会把这一万多个哈希槽均匀地分布到多个节点上，每个节点负责一部分哈希槽。&lt;/p>
&lt;p>实际上刚建立集群的时候，每个 Redis 实例并不知道别的实例分配了哪些槽位。他们之间会进行扩散转发哈希槽信息，等都建立链接以后，就有了对应的关系了。客户端会把哈希槽信息缓存到本地，在客户端访问时，会根据算法算出 key 对应的哈希槽位，然后直接访问对应的节点，就好像这个分片的操作对于客户端来说是完全无感的&lt;/p>
&lt;h2 id="参考文献">参考文献&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.cnblogs.com/lgx211/p/12456859.html">多图文，详细介绍 mysql 各个集群方案&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cnblogs.com/ricklz/p/17335755.html">MySQL 中常见的几种高可用架构部署方案&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://xiaolincoding.com/mysql/log/how_update.html#%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84">MySQL 日志：undo log、redo log、binlog 有什么用？&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://juejin.cn/post/6981745007552102407">MySQL 半同步复制及半同步复制增强&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://time.geekbang.org/column/article/272852">06 | 数据同步：主从库如何实现数据一致？&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://time.geekbang.org/column/article/274483">07 | 哨兵机制：主库挂了，如何不间断服务？&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://freegeektime.com/100056701/275337/">08 | 哨兵集群：哨兵挂了，主从库还能切换吗？&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://xiaolincoding.com/redis/base/redis_interview.html#%E9%9B%86%E7%BE%A4%E8%84%91%E8%A3%82%E5%AF%BC%E8%87%B4%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%80%8E%E4%B9%88%E5%8A%9E">小林 coding | Redis 常见面试题&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>深入理解分布式锁的原理和技术选型</title><link>https://vinci-217.github.io/blog/lock/</link><pubDate>Wed, 22 Jan 2025 10:28:35 +0800</pubDate><guid>https://vinci-217.github.io/blog/lock/</guid><description>&lt;p>分布式锁是一种常用的技术，在分布式环境下，为了避免多个进程或线程同时操作同一资源造成冲突，引入分布式锁机制。本文将介绍分布式锁的原理和使用场景，并通过 Redis、Zookeeper、Redisson 等中间件来实现分布式锁。&lt;/p>
&lt;h2 id="分布式锁的主要特性">分布式锁的主要特性&lt;/h2>
&lt;ul>
&lt;li>互斥：不同线程之间互斥，只有一个线程能持有锁。&lt;/li>
&lt;li>超时机制：代码耗时过长，网络原因等，导致锁一直被占用，造成死锁，所以引入超时机制，超过指定时间自动释放锁。&lt;/li>
&lt;li>可重入性：当前请求的节点 + 线程唯一标识，可以再次获取同一把锁&lt;/li>
&lt;li>公平性：锁唤醒时候，按照顺序唤醒，不公平的话，有可能出现饥饿现象。&lt;/li>
&lt;/ul>
&lt;h2 id="分布式锁的原理与实现">分布式锁的原理与实现&lt;/h2>
&lt;p>分布式锁的目的是区别于 JVM 单机锁。&lt;/p>
&lt;p>JVM 单机锁就是在同一个 JVM 中的锁。比如你使用了 synchronized 关键字，那么就是在这同一个 JVM 中，同一时刻只能有一个线程持有锁，其他线程只能等待。但是当你的后端服务是分布式集群部署的方式，那么 JVM 单机锁就无法满足需求了。因为你这个 JVM 锁住了，我的线程打到了另一台机器上，那就相当于没锁住，所以我们需要分布式锁。分布式锁的目的就是在多个 JVM 层之前设置的锁，这样就可以在多个机器上实现同一把锁的目的。&lt;/p>
&lt;p>&lt;img src="image/image-3.png" alt="alt text">&lt;/p>
&lt;p>分布式锁的原理就是在多个机器上设置同一把锁，这个锁通常通过某些中间件实现。当一个线程想要获取锁的时候，首先会去尝试获取锁，如果获取成功，那么就可以执行任务，如果获取失败，那么就只能等待，直到锁被释放。&lt;/p>
&lt;h3 id="mysql">MySQL&lt;/h3>
&lt;h4 id="基于索引">基于索引&lt;/h4>
&lt;p>基于索引的实现，是通过在数据库的某个字段上加了唯一的索引，那么只有一个线程能够对写入同一个数据，其他的线程由于索引的唯一性而无法写入，只能等待资源释放——这个唯一值被 DELETE 掉，那么可以重新写入来获取锁&lt;/p>
&lt;p>我们可以先创建一个类似的表：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sql" data-lang="sql">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">CREATE&lt;/span> &lt;span style="color:#66d9ef">TABLE&lt;/span> &lt;span style="color:#f92672">`&lt;/span>database_lock&lt;span style="color:#f92672">`&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">`&lt;/span>id&lt;span style="color:#f92672">`&lt;/span> BIGINT &lt;span style="color:#66d9ef">NOT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span> AUTO_INCREMENT,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">`&lt;/span>resource&lt;span style="color:#f92672">`&lt;/span> int &lt;span style="color:#66d9ef">NOT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span> &lt;span style="color:#66d9ef">COMMENT&lt;/span> &lt;span style="color:#e6db74">&amp;#39;锁定的资源&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">`&lt;/span>description&lt;span style="color:#f92672">`&lt;/span> varchar(&lt;span style="color:#ae81ff">1024&lt;/span>) &lt;span style="color:#66d9ef">NOT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span> &lt;span style="color:#66d9ef">DEFAULT&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">COMMENT&lt;/span> &lt;span style="color:#e6db74">&amp;#39;描述&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">PRIMARY&lt;/span> &lt;span style="color:#66d9ef">KEY&lt;/span> (&lt;span style="color:#f92672">`&lt;/span>id&lt;span style="color:#f92672">`&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">UNIQUE&lt;/span> &lt;span style="color:#66d9ef">KEY&lt;/span> &lt;span style="color:#f92672">`&lt;/span>uiq_idx_resource&lt;span style="color:#f92672">`&lt;/span> (&lt;span style="color:#f92672">`&lt;/span>resource&lt;span style="color:#f92672">`&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>) ENGINE&lt;span style="color:#f92672">=&lt;/span>InnoDB &lt;span style="color:#66d9ef">DEFAULT&lt;/span> CHARSET&lt;span style="color:#f92672">=&lt;/span>utf8mb4 &lt;span style="color:#66d9ef">COMMENT&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;数据库分布式锁表&amp;#39;&lt;/span>;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>其中的 resource 就是锁的名字，locked_at 就是锁的创建时间。&lt;/p>
&lt;p>这里我们给数据库加了一个唯一索引，目的是对资源进唯一性约束。这样在写入同一个数据时，只能有一个线程写入，其他线程只能失败。通过这样的方法就实现了一个分布式锁。&lt;/p>
&lt;p>这种锁的实现比较简单，但也会面临锁无法过期，锁的可靠性依赖于 MySQL 数据库的可用性等等问题。&lt;/p>
&lt;h4 id="基于乐观锁">基于乐观锁&lt;/h4>
&lt;p>基于乐观锁的实现原理是多个线程可以同时对资源进行修改，但最终只能有一个修改成功，其他的回退。乐观锁的实现一般是基于版本号的机制，比如在更新数据时，先获取当前版本号，然后更新数据，再更新版本号。如果更新失败，说明数据已经被其他线程更新过了，那么就需要重试。&lt;/p>
&lt;p>例如建立如下的数据库表：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sql" data-lang="sql">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">CREATE&lt;/span> &lt;span style="color:#66d9ef">TABLE&lt;/span> &lt;span style="color:#f92672">`&lt;/span>optimistic_lock&lt;span style="color:#f92672">`&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">`&lt;/span>id&lt;span style="color:#f92672">`&lt;/span> BIGINT &lt;span style="color:#66d9ef">NOT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span> AUTO_INCREMENT,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">`&lt;/span>resource&lt;span style="color:#f92672">`&lt;/span> int &lt;span style="color:#66d9ef">NOT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span> &lt;span style="color:#66d9ef">COMMENT&lt;/span> &lt;span style="color:#e6db74">&amp;#39;锁定的资源&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">`&lt;/span>&lt;span style="color:#66d9ef">version&lt;/span>&lt;span style="color:#f92672">`&lt;/span> int &lt;span style="color:#66d9ef">NOT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span> &lt;span style="color:#66d9ef">COMMENT&lt;/span> &lt;span style="color:#e6db74">&amp;#39;版本信息&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">`&lt;/span>created_at&lt;span style="color:#f92672">`&lt;/span> datetime &lt;span style="color:#66d9ef">COMMENT&lt;/span> &lt;span style="color:#e6db74">&amp;#39;创建时间&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">`&lt;/span>updated_at&lt;span style="color:#f92672">`&lt;/span> datetime &lt;span style="color:#66d9ef">COMMENT&lt;/span> &lt;span style="color:#e6db74">&amp;#39;更新时间&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">`&lt;/span>deleted_at&lt;span style="color:#f92672">`&lt;/span> datetime &lt;span style="color:#66d9ef">COMMENT&lt;/span> &lt;span style="color:#e6db74">&amp;#39;删除时间&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">PRIMARY&lt;/span> &lt;span style="color:#66d9ef">KEY&lt;/span> (&lt;span style="color:#f92672">`&lt;/span>id&lt;span style="color:#f92672">`&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">UNIQUE&lt;/span> &lt;span style="color:#66d9ef">KEY&lt;/span> &lt;span style="color:#f92672">`&lt;/span>uiq_idx_resource&lt;span style="color:#f92672">`&lt;/span> (&lt;span style="color:#f92672">`&lt;/span>resource&lt;span style="color:#f92672">`&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>) ENGINE&lt;span style="color:#f92672">=&lt;/span>InnoDB &lt;span style="color:#66d9ef">DEFAULT&lt;/span> CHARSET&lt;span style="color:#f92672">=&lt;/span>utf8mb4 &lt;span style="color:#66d9ef">COMMENT&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;数据库分布式锁表&amp;#39;&lt;/span>;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>每个线程的执行逻辑如下：&lt;/p>
&lt;ul>
&lt;li>获取资源： SELECT resource, version FROM optimistic_lock WHERE id = 1&lt;/li>
&lt;li>执行业务逻辑&lt;/li>
&lt;li>更新资源：UPDATE optimistic_lock SET resource = resource -1, version = version + 1 WHERE id = 1 AND version = oldVersion&lt;/li>
&lt;/ul>
&lt;p>通过比对修改后的 version 和修改之前的 oldVersion，如果一致，说明数据没有被其他线程更新过，那么就更新成功，否则就需要重试。&lt;/p>
&lt;p>这种锁的实现比较复杂，但也能保证数据的一致性。在检测数据冲突时并不依赖数据库本身的锁机制，不会影响请求的性能。但是需要对表的设计增加额外的字段，增加了数据库的冗余。并且高并发的情况下增加了重试的次数，会影响性能。&lt;/p>
&lt;h4 id="基于悲观锁">基于悲观锁&lt;/h4>
&lt;p>基于悲观锁的实现原理是多个线程只能一个一个地获取锁，直到获取锁的线程释放锁，其他线程才能获取锁。我们在基于 MySQL 的悲观锁的实现中，一般采用 MySQL 自带的锁机制，比如 SELECT &amp;hellip; FOR UPDATE。数据库会在查询的过程中加上排他锁，那么这样别的事务就无法对该资源进行修改。&lt;/p>
&lt;p>基于悲观锁的实现过程如下：&lt;/p>
&lt;ul>
&lt;li>获取资源： SELECT * FROM optimistic_lock WHERE id = 1 FOR UPDATE&lt;/li>
&lt;li>执行业务逻辑&lt;/li>
&lt;li>释放资源：COMMIT&lt;/li>
&lt;/ul>
&lt;p>相当于我们基于 SELECT &amp;hellip; FOR UPDATE 获取了这行数据的锁，并且在同一事务下执行修改的业务逻辑，最终在 COMMIT 提交事务时释放锁。&lt;/p>
&lt;p>这种锁的的实现也比较简单，主要是基于数据库的事务和行锁。但要注意行锁失效的情况。并且每次请求都会额外产生加锁的开销且未获取到锁的请求将会阻塞等待锁的获取，在高并发环境下，容易造成大量请求阻塞，影响系统可用性。&lt;/p>
&lt;h3 id="zookeeper">Zookeeper&lt;/h3>
&lt;p>基于 Zookeeper 的分布式锁，主要来自于 Zookeeper 的两个机制&lt;/p>
&lt;ul>
&lt;li>临时顺序节点机制&lt;/li>
&lt;/ul>
&lt;p>Zookeeper 的节点是一个类似于文件系统的目录结构，每个节点都可以设置临时顺序节点，也就是说，在创建节点时，可以指定一个顺序，然后 Zookeeper 会根据这个顺序来分配节点的唯一标识符。除此以外节点也可以被标记为持久节点，持久节点会一直存在直到主动删除。&lt;/p>
&lt;ul>
&lt;li>watch 机制&lt;/li>
&lt;/ul>
&lt;p>Zookeeper 的 watch 机制允许用户在指定的节点上注册一个监听器，当节点发生变化时，Zookeeper 会通知监听器，并触发监听器的回调函数。&lt;/p>
&lt;p>基于这两个机制，我们可以实现一个基于 Zookeeper 的分布式锁。&lt;/p>
&lt;p>我们首先建立一个父节点，这个父节点是一个持久节点，用来表示共享资源。然后在父节点下创建临时顺序节点，这个临时顺序节点用来标识当前获得锁的线程。最终在父节点之下建立了一个类似于队列的结构。然后判断当前节点是不是最小的节点，如果是最小的节点，那么就获取锁，否则就监听前一个节点的删除事件，直到获得锁。每次节点使用完共享资源，就会删除该节点，进而释放锁，后面的节点通过 watch 监听前一个节点的删除事件，获得锁。&lt;/p>
&lt;p>&lt;img src="image/image.png" alt="alt text">&lt;/p>
&lt;p>Zookeeper 实现分布式锁的好处就是可以实现顺序的公平锁。并且可以实现较强一致性，所有的操作都可以被保证是原子性的。假如某个节点宕机了，那么会自动释放锁，防止了死锁，提高了系统的可用性。&lt;/p>
&lt;p>但是坏处就是，节点的创建和销毁对性能开销比较大，在高并发的环境下可能有较大的性能问题。另外，Zookeeper 的 watch 机制也会增加系统的复杂度，需要考虑节点的删除和创建的时机，以及节点的连接状态等。&lt;/p>
&lt;h3 id="redis">Redis&lt;/h3>
&lt;p>用 Redis 实现分布式锁，利用的是 SETNX+EXPIRE 命令。&lt;/p>
&lt;p>SETNX 命令的作用是设置一个 key，当 key 不存在时，返回 1，如果 key 已经存在，返回 0。EXPIRE 命令的作用是设置一个 key 的过期时间，当 key 过期时，Redis 会自动删除该 key。&lt;/p>
&lt;p>一般这两条命令写在一行来确保指令的原子性，如：&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-redis" data-lang="redis">SETNX lock_key some_unique_value EXPIRE lock_key 10 # 设置过期时间为10秒
&lt;/code>&lt;/pre>&lt;p>其中 lock_key 是锁的名字，some_unique_value 是唯一的值，10 是过期时间。&lt;/p>
&lt;p>通常我们会在加锁的过程中，对 value 设置一个唯一的 UUID。当解锁的时候，我们会判断当前线程的这个 UUID 是否和锁的 value 一样，如果一样才能解锁。这样可以防止其他线程对锁进行误操作。&lt;/p>
&lt;p>解锁的过程通常分为：获取锁变量，检查锁变量的 value 是否和当前线程的 UUID 一致，如果一致则删除变量。通常为了保证解锁过程的原子性，我们会对这个操作进行 Lua 脚本的封装。&lt;/p>
&lt;p>当两个线程同时执行这个命令时，只有一个线程会成功对 lock_key 的值进行修改，其他线程会失败，这样就达到了分布式锁的目的。&lt;/p>
&lt;p>基于 Redis 实现分布式锁，由于是对值的修改，性能比较高。但是如果是在 Redis 集群环境下，由于 Redis 集群同步是异步的。如果在 Master 节点上设置锁，Slave 节点可能没有同步到最新的数据。此时 Master 节点崩溃了但是理论上锁不应当被释放，但由于 Master 的宕机导致了锁物理上被释放，所以其他客户端可能会加新的锁来对共享资源进行修改，这样就出现了问题。&lt;/p>
&lt;p>解决这个问题的方法就是 RedLock 算法——也就是 Redisson 的实现原理。&lt;/p>
&lt;h3 id="redisson">Redisson&lt;/h3>
&lt;p>用 Redisson 实现分布式锁，本质上是封装了 Reids 的操作来实现的。&lt;/p>
&lt;p>Redisson 的公平锁的实现原理类似于 ReentrankLock 的公平锁机制，主要维护一个等待队列，通过控制锁的获取顺序来实现。&lt;/p>
&lt;p>Redisson 的看门狗机制目的是检查锁的状态，自动管理分布式锁过期时间。其实现主要通过一个后台线程（俗称看门狗），每隔锁的 1/3 时间检查锁的状态，只要持有锁的线程仍在执行且没有主动释放锁，看门狗就会持续进行续期操作。如果没有线程持有锁，看门狗就会自动释放锁。&lt;/p>
&lt;p>&lt;img src="image/image-1.png" alt="alt text">&lt;/p>
&lt;p>Redisson 通过 RedLock 算法，保证了集群环境中锁的可靠性。&lt;/p>
&lt;p>RedLock 算法的主要目的是为了解决 Master 节点宕机导致锁的释放问题。RedLock 算法的基本思路是，在多个 Redis 节点上同时加锁，只要大多数 Redis 节点都加锁成功，那么加锁成功；如果加锁失败，则释放所有锁并重试。&lt;/p>
&lt;p>RedLock 算法的流程如下：&lt;/p>
&lt;ol>
&lt;li>客户端获取当前时间戳。&lt;/li>
&lt;li>客户端在每个 Redis 节点上尝试用相同的锁名和 UUID 获取锁，并设置一个较短的过期时间。获取成功则记录加锁节点，否则记录失败节点。并记录加锁的总用时。&lt;/li>
&lt;li>如果成功加锁的节点大于等于 N/2+1（N 为 Redis 节点数），并且获取锁的总时间小于锁的过期时间，则认为加锁成功并执行业务逻辑；否则认为获取锁失败，释放所有锁&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="image/image-2.png" alt="alt text">&lt;/p>
&lt;p>Redisson 通过唯一标识与计数器实现了锁的可重入的特性：&lt;/p>
&lt;ol>
&lt;li>每个锁在 Redis 中存储为一个键，键的值是一个唯一标识符（通常是 UUID）和一个计数器。当一个线程第一次获取锁时，Redisson 会在 Redis 中创建一个键，值为当前线程的唯一标识符，并将计数器设置为 1。&lt;/li>
&lt;li>如果同一个线程再次请求获取同一个锁，Redisson 会检测到该线程已经持有锁，因为 Redis 中的值包含该线程的唯一标识符。此时，Redisson 只会增加计数器，而不会再次申请锁。&lt;/li>
&lt;li>当线程释放锁时，Redisson 会减少计数器。只有当计数器减少到 0 时，锁才会真正被释放，Redis 中的键才会被删除。&lt;/li>
&lt;/ol>
&lt;h2 id="分布式锁的选用">分布式锁的选用&lt;/h2>
&lt;h3 id="基于数据库">基于数据库&lt;/h3>
&lt;p>基于数据库的锁，主要是基于数据库的特性：唯一索引、乐观锁版本号自行比对，悲观锁 SELECT &amp;hellip; FOR UPDATE（数据库层面的锁）等。但也有很多问题，所以实际生产环境很少考虑用这把锁。&lt;/p>
&lt;p>&lt;strong>缺点：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>性能问题：数据库的锁基于磁盘数据的 CRUD 操作，必然会造成性能问题。&lt;/li>
&lt;li>可靠性问题：基于数据库的锁，如果数据库宕机，锁也会被释放，导致数据不一致。可以通过集群部署的方式来提高可靠性。&lt;/li>
&lt;li>过期问题：数据库的数据无法自动过期，如果锁一直没有释放，会造成死锁。只能通过自行配置定时任务来清理过期锁。&lt;/li>
&lt;li>重入问题：基于数据库的锁，如果同一个线程再次请求获取同一个锁，数据库会检测到该线程已经持有锁，但是不会再次申请锁，所以无法实现重入。可以通过人为模拟其他重入锁的实现方式（记录唯一 ID，下次访问让这个 ID 对应的计数器值加一，释放锁时让这个 ID 对应的计数器值减一），来实现重入锁。&lt;/li>
&lt;/ol>
&lt;h3 id="基于-zookeeper">基于 Zookeeper&lt;/h3>
&lt;p>基于 Zookeeper 的锁，主要是基于 Zookeeper 的特性：临时顺序节点、watch 机制等。Zookeeper 本身的集群设计就是为了保证强一致性，所以基于 Zookeeper 的锁可以实现较强的一致性。&lt;/p>
&lt;p>&lt;strong>优点：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>公平性：由于临时顺序节点的机制，Zookeeper 实现的分布式锁天然保证了锁的公平性。&lt;/li>
&lt;li>可重入性：Zookeeper 通过会话 ID 来判断是不是同一个线程访问，所以天然也实现了可重入性。&lt;/li>
&lt;li>锁释放问题：节点释放锁以后会自动被 Zookeeper 删除这个节点，不会出现锁释放导致的问题。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>缺点：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>性能问题：由于关于锁的获取需要节点的创建和释放，并且在集群环境中只能由 Leader 节点来进行操作，所以性能会受到影响。&lt;/li>
&lt;li>其实 Zookeeper 也会有并发问题，在网络抖动的环境下，客户端有时候会突然连不上 Zookeeper，所以锁会被释放供后面的线程获取。但是因为 ZK 有重试机制，所以这种情况很少发生。&lt;/li>
&lt;/ol>
&lt;h3 id="基于-redisson">基于 redisson&lt;/h3>
&lt;p>基于 Redisson 的锁，主要是基于 Redisson 的特性：RedLock 算法、可重入锁等。Redisson 实现了分布式锁的功能，并且提供了一些高级功能，比如：可重入锁、过期锁自动续期、分布式锁监听器等。&lt;/p>
&lt;p>&lt;strong>优点：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>集群问题：客户端 A 从 master 节点获取到锁后，由于 Redis 集群部署数据通过异步复制，可能出现 master 宕机以后锁变量未能及时同步到 slave 节点上的情况。当 slave 节点晋升为 master 节点以后，客户端 B 就可以从新的 master 节点中获取锁，这样就导致了一把锁同时被两个客户端获取，破坏了锁的互斥性。而 Redission 的 RedLock 算法一定程度上减少了这个问题的发生。&lt;/li>
&lt;li>可重入性：Redisson 通过锁的计数器变量实现了可重入性。&lt;/li>
&lt;li>自动续期：Redisson 采用看门狗机制，每隔 1/3 的时间检查锁的状态看是否被客户端占有，如果持有锁的线程仍在执行且没有主动释放锁，则自动续期；如果客户端宕机则自动释放锁。&lt;/li>
&lt;li>公平锁：Redisson 通过维护一个等待队列，按照先来先服务的原则，保证了锁的公平性。&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>缺点：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>依赖于 Redis：如果 Redis 宕机或者不可用，那么 Redisson 的锁也会失效。&lt;/li>
&lt;li>性能问题：RedLock 算法的执行过程中，也可能会面临一些加锁解锁的性能成本，以及系统时钟比对的问题&lt;/li>
&lt;/ol>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>实际生产环境中，我们一般推荐 ZK 或者 Redis 分布式锁。相比之下，ZK 的锁的可靠性更高，Redis 的锁的性能更好。具体使用那种还是取决于自己的业务需要。&lt;/p>
&lt;h2 id="参考文献">参考文献&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://blog.csdn.net/u013474436/article/details/104924782">基于 MySQL 实现的分布式锁&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.csdn.net/weixin_45683778/article/details/144564485">【MySQL】优雅的使用 MySQL 实现分布式锁&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.csdn.net/Fireworkit/article/details/136968331">Zookeeper 实现分布式锁（Zk 分布式锁）&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mp.weixin.qq.com/s/hvTx6_WSZ82ok3na7L1IiA">阿里技术-分布式锁实现原理与最佳实践&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>